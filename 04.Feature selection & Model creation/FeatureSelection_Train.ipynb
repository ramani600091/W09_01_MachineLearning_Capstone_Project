{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd447a69",
   "metadata": {},
   "source": [
    "# Declaring Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c71f12cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas                    as pd\n",
    "import numpy                     as np\n",
    "import matplotlib.pyplot         as plt\n",
    "import UnivariateFunctions       as dpm\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from   sklearn.model_selection   import train_test_split \n",
    "from   sklearn.preprocessing     import StandardScaler\n",
    "from   sklearn.feature_selection import SelectKBest\n",
    "from   sklearn.feature_selection import chi2\n",
    "from   sklearn.feature_selection import RFE\n",
    "from   sklearn.linear_model      import LogisticRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db43211f",
   "metadata": {},
   "source": [
    "# Get Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2071a0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset,df,ind,dep,x_train,x_test,y_train,ytest= dpm.getProcessedData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19c94637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Funciton definition for Feature Selection\n",
    "# def selectkbest(indep_X, dep_Y, n):\n",
    "#     test = SelectKBest(score_func=chi2, k=n)\n",
    "#     fit1 = test.fit(indep_X, dep_Y)\n",
    "#     selected_features = indep_X.columns[fit1.get_support()]   # <--- Store column names\n",
    "#     selectk_features = fit1.transform(indep_X)\n",
    "#     return selectk_features, selected_features\n",
    "\n",
    "# Funciton definition for Feature Selection\n",
    "def selectkbest(indep_X,dep_Y,n):\n",
    "        test = SelectKBest(score_func=chi2, k=n)\n",
    "        fit1= test.fit(indep_X,dep_Y)\n",
    "        selectk_features = fit1.transform(indep_X)\n",
    "        return selectk_features\n",
    "\n",
    "# Definition of Scalar Matrix\n",
    "def split_scalar(indep_X,dep_Y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(indep_X, dep_Y, test_size = 0.25, random_state = 0)\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)    \n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Definition of Confusion Matric    \n",
    "def cm_prediction(classifier,X_test):\n",
    "     y_pred = classifier.predict(X_test)\n",
    "        \n",
    "        # Making the Confusion Matrix\n",
    "     from sklearn.metrics import confusion_matrix\n",
    "     cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "     from sklearn.metrics import accuracy_score \n",
    "     from sklearn.metrics import classification_report\n",
    "        \n",
    "     Accuracy=accuracy_score(y_test, y_pred )\n",
    "        \n",
    "     report=classification_report(y_test, y_pred)\n",
    "     return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "\n",
    "# Definition for Logistic Regression \n",
    "def logistic(X_train,y_train,X_test):       \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        classifier = LogisticRegression(random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm      \n",
    "\n",
    "def svm_gridsearch(X_train,y_train,X_test):\n",
    "    \n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.svm import SVR\n",
    "    from sklearn.svm import SVC  # ✅ use SVC, not SVR\n",
    "    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "    \n",
    "    \n",
    "    param_grid = {'kernel':['rbf','poly','sigmoid','linear'],\n",
    "                  'C':[10,100,1000,2000,3000],'gamma':['auto','scale']} \n",
    "#     classifier = GridSearchCV(SVR(), param_grid, refit = True, verbose = 3,n_jobs=-1) \n",
    "\n",
    "    # Use SVC for classification\n",
    "    grid = GridSearchCV(\n",
    "        estimator=SVC(random_state=0),\n",
    "        param_grid=param_grid,\n",
    "        cv=2,\n",
    "        verbose=1,\n",
    "        n_jobs=1   # ✅ use fewer cores to avoid crashing\n",
    "    )\n",
    "\n",
    "    \n",
    "    \n",
    "    # fitting the model for grid search \n",
    "    grid.fit(X_train, y_train) \n",
    "    \n",
    "    y_pred = grid.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)    \n",
    "    \n",
    "#     classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "    return grid.best_estimator_, acc, report, X_test, y_test, cm\n",
    "#     return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "    \n",
    "    \n",
    "# Definition for SVM Linear Regression  \n",
    "def svm_linear(X_train,y_train,X_test):\n",
    "                \n",
    "        from sklearn.svm import SVC\n",
    "        classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "\n",
    "    \n",
    "    \n",
    "# Definition of Support Vector Matrix    \n",
    "def svm_NL(X_train,y_train,X_test):\n",
    "                \n",
    "        from sklearn.svm import SVC\n",
    "        classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "# Definition of Navie Regression\n",
    "def Navie(X_train,y_train,X_test):       \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.naive_bayes import GaussianNB\n",
    "        classifier = GaussianNB()\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm         \n",
    "    \n",
    "# Definition for K-Nearest Neighbor Regression    \n",
    "def knn(X_train,y_train,X_test):\n",
    "           \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "# Definition for Decision Tree Regression\n",
    "def Decision(X_train,y_train,X_test):\n",
    "        \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm      \n",
    "\n",
    "# Defnition for Random Forest Regression\n",
    "def random(X_train,y_train,X_test):\n",
    "        \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "    \n",
    "def selectk_Classification(acclog,grid,accsvml,accsvmnl,accknn,accnav,accdes,accrf): \n",
    "    \n",
    "    dataframe=pd.DataFrame(index=['ChiSquare'],columns=['Logistic','GridCV','SVMl_linear','SVMnl_rbf','KNN','Navie','Decision','Random'])\n",
    "    for number,idex in enumerate(dataframe.index):      \n",
    "        dataframe['Logistic'][idex]   =acclog[number]       \n",
    "#         dataframe['GridCV'][idex]     =grid[number]       \n",
    "        dataframe['SVMl_linear'][idex]=accsvml[number]\n",
    "        dataframe['SVMnl_rbf'][idex]  =accsvmnl[number]\n",
    "        dataframe['KNN'][idex]        =accknn[number]\n",
    "        dataframe['Navie'][idex]      =accnav[number]\n",
    "        dataframe['Decision'][idex]   =accdes[number]\n",
    "        dataframe['Random'][idex]     =accrf[number]\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1dca91",
   "metadata": {},
   "source": [
    "# Reading CSV File as a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a3a5ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"HeartFailureDataset v1.csv\",index_col=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ac1d69",
   "metadata": {},
   "source": [
    "# Data Pre-processing\n",
    "#### 1) Convert all NaN values to '0' for the columns  ['gluc', 'smoke','alco','active']\n",
    "#### 2) Convert all NaN values to 'False' or 'True' for the column ['cardio']  as this is to be a Categorical Column\n",
    "#### 3) Splitting Independent & Dependent dataset\n",
    "#### 3) Converting Negative (-ve) values to 0 as this is not allowed for classificaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f5a3411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind [Before -ve removal]:-\n",
      " age             29\n",
      "height          55\n",
      "weight          30\n",
      "ap_hi         -140\n",
      "ap_lo            0\n",
      "cholesterol      1\n",
      "gluc             1\n",
      "smoke            0\n",
      "alco             0\n",
      "active           0\n",
      "gender_Male      0\n",
      "dtype: int64\n",
      "\n",
      "ind [Afer -ve removal]:-\n",
      " age            29\n",
      "height         55\n",
      "weight         30\n",
      "ap_hi           0\n",
      "ap_lo           0\n",
      "cholesterol     1\n",
      "gluc            1\n",
      "smoke           0\n",
      "alco            0\n",
      "active          0\n",
      "gender_Male     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df2 = dataset\n",
    "df2 = pd.get_dummies(dataset, drop_first=True)\n",
    "df2 = df2.drop('id',axis=1)\n",
    "\n",
    "# 1) Convert all NaN values to '0' for the columns ['gluc', 'smoke','alco','active']\n",
    "cols_numeric      = ['gluc', 'smoke','alco','active']\n",
    "df2[cols_numeric] = np.where(df2[cols_numeric].isna(), 0, 1)\n",
    "\n",
    "# 2) Column where NaN -> False and others -> True\n",
    "df2['cardio'] = np.where(df2['cardio'].isna(), False, True)\n",
    "\n",
    "# Convert age from days to years (whole number)\n",
    "df2['age'] = (df2['age'] / 365).astype(int)\n",
    "\n",
    "# Correct: keep original 0/1 values instead of making all True\n",
    "df2['cardio'] = df2['cardio'].fillna(0).astype(int)\n",
    "# df2['cardio'] = df2['cardio'].fillna(0).astype(bool)\n",
    "\n",
    "# 3) Splitting Independent & Dependent dataset\n",
    "ind  =df2.drop(['cardio'], axis=1)\n",
    "dep  =df2['cardio']\n",
    "indep_X= ind \n",
    "dep_Y  = dep\n",
    "\n",
    "# 3) Converting Negative (-ve) values to 0 as this is not allowed for classificaiton\n",
    "print(\"ind [Before -ve removal]:-\\n\",indep_X.min()) # Check if there is any -ve values\n",
    "indep_X[indep_X < 0] = 0\n",
    "print(\"\\nind [Afer -ve removal]:-\\n\",indep_X.min()) # Check if the -ve values are removed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f67fab94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 50 168  62 ...   1   0   1]\n",
      " [ 55 156  85 ...   3   0   1]\n",
      " [ 51 165  64 ...   3   0   0]\n",
      " ...\n",
      " [ 64 168  74 ...   1   0   1]\n",
      " [ 60 160 128 ...   2   0   0]\n",
      " [ 59 159  64 ...   1   0   1]]\n"
     ]
    }
   ],
   "source": [
    "# Adding 7 -feature parameters  (ie.0-7 = 8 inputs)\n",
    "# The input-parameters are:\n",
    "#    'age', 'height', 'weight', 'ap_hi', 'ap_lo', 'cholesterol', 'gluc', 'gender_Male'\n",
    "\n",
    "kbest=selectkbest(indep_X,dep_Y,8)   \n",
    "print(kbest)\n",
    "\n",
    "acclog     =[]\n",
    "accsvml    =[]\n",
    "accsvmnl   =[]\n",
    "accknn     =[]\n",
    "accnav     =[]\n",
    "accdes     =[]\n",
    "accrf      =[]\n",
    "grid       =[]\n",
    "classifiers=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3424f462",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=split_scalar(kbest,dep_Y)   \n",
    "    \n",
    "        \n",
    "classifier,Accuracy,report,X_test,y_test,cm=logistic(X_train,y_train,X_test)\n",
    "acclog.append(Accuracy)\n",
    "classifiers.append(classifier)\n",
    "\n",
    "# classifier,Accuracy,report,X_test,y_test,cm=svm_gridsearch(X_train,y_train,X_test)\n",
    "# grid.append(Accuracy)\n",
    "# classifiers.append(classifier)\n",
    "\n",
    "\n",
    "classifier,Accuracy,report,X_test,y_test,cm=svm_linear(X_train,y_train,X_test)  \n",
    "accsvml.append(Accuracy)\n",
    "classifiers.append(classifier)\n",
    "    \n",
    "classifier,Accuracy,report,X_test,y_test,cm=svm_NL(X_train,y_train,X_test)  \n",
    "accsvmnl.append(Accuracy)\n",
    "classifiers.append(classifier)\n",
    "    \n",
    "classifier,Accuracy,report,X_test,y_test,cm=knn(X_train,y_train,X_test)  \n",
    "accknn.append(Accuracy)\n",
    "classifiers.append(classifier)\n",
    "    \n",
    "classifier,Accuracy,report,X_test,y_test,cm=Navie(X_train,y_train,X_test)  \n",
    "accnav.append(Accuracy)\n",
    "classifiers.append(classifier)\n",
    "    \n",
    "classifier,Accuracy,report,X_test,y_test,cm=Decision(X_train,y_train,X_test)  \n",
    "accdes.append(Accuracy)\n",
    "classifiers.append(classifier)\n",
    "    \n",
    "classifier,Accuracy,report,X_test,y_test,cm=random(X_train,y_train,X_test)  \n",
    "accrf.append(Accuracy)\n",
    "classifiers.append(classifier)\n",
    "    \n",
    "result=selectk_Classification(acclog,grid,accsvml,accsvmnl,accknn,accnav,accdes,accrf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0812758d",
   "metadata": {},
   "source": [
    "# Displaying the accuracy of every model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a38bbd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+----------+---------------+-------------+----------+----------+------------+----------+\n",
      "|           |   Logistic |   GridCV |   SVMl_linear |   SVMnl_rbf |      KNN |    Navie |   Decision |   Random |\n",
      "+===========+============+==========+===============+=============+==========+==========+============+==========+\n",
      "| ChiSquare |   0.722258 |      nan |      0.722911 |    0.726991 | 0.691743 | 0.641808 |   0.642298 | 0.694027 |\n",
      "+-----------+------------+----------+---------------+-------------+----------+----------+------------+----------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "print(tabulate(result, headers='keys', tablefmt='grid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48811865",
   "metadata": {},
   "source": [
    "# Finding the Best Model Automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d084465b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best Model: SVMnl_rbf\n",
      "📈 Accuracy: 0.726991\n",
      "🔢 Index Position: 1\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(result, index=['ChiSquare'])\n",
    "\n",
    "# ensure all values are numeric\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# find best model\n",
    "best_model = df.loc['ChiSquare'].idxmax()\n",
    "best_score = df.loc['ChiSquare'].max()\n",
    "best_index = df.loc['ChiSquare'].values.argmax()\n",
    "\n",
    "print(f\"✅ Best Model: {best_model}\")\n",
    "print(f\"📈 Accuracy: {best_score:.6f}\")\n",
    "print(f\"🔢 Index Position: {best_index}\")\n",
    "\n",
    "regressor = classifiers[best_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b08950",
   "metadata": {},
   "source": [
    "# Save and implement the best model found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b55e5072",
   "metadata": {},
   "outputs": [],
   "source": [
    "##-MODEL SAVE: \n",
    "import pickle\n",
    "filename = \"CapstoneProject_FeatureSelection.sav\"\n",
    "pickle.dump(regressor,open(filename,'wb'))       ## WRITE BINARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc489ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'height',\n",
       " 'weight',\n",
       " 'ap_hi',\n",
       " 'ap_lo',\n",
       " 'cholesterol',\n",
       " 'gluc',\n",
       " 'smoke',\n",
       " 'alco',\n",
       " 'active',\n",
       " 'gender_Male']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quan,qual = dpm.getQuanQual(df2)\n",
    "quan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3e7ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d604a3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99abdb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##-MODEL LOAD\n",
    "\n",
    "loaded_model = pickle.load(open(filename,'rb'))  ## READ BINARY\n",
    "\n",
    "\n",
    "age        =48\n",
    "height     =169\n",
    "weight     =82\n",
    "ap_hi      =150\n",
    "ap_lo      =100\n",
    "cholesterol=0\n",
    "gluc       =0\n",
    "active     = 0\n",
    "gender_Male=0\n",
    "\n",
    "\n",
    "result     =loaded_model.predict([[age,height,ap_hi,ap_lo,cholesterol,gluc,active,gender_Male]])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ac2bfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagonized with Cardiovascular disorder\n"
     ]
    }
   ],
   "source": [
    "if result[0]==1:\n",
    "    print(\"Diagonized with Cardiovascular disorder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb43ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
